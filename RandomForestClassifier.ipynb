# ===============================
# Random Forest Classifier for Stress Level Prediction
# ===============================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                           f1_score, confusion_matrix, classification_report)


df = pd.read_csv("./StressLevelDataset.csv")

# Print information of the dataset
print("\nDataset Info:")
print(df.info())

# Print sample rows of the dataset
print("\nFirst 5 rows:")
print(df.head())

# ===============================
# Data Preprocessing
# ===============================
print("\nData Preprocessing")
# Fill empty values with median
missing_records = df.isnull().sum()
if (missing_records.sum() > 0):
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    medians = df[numeric_cols].median()
    df[numeric_cols] = df[numeric_cols].fillna(medians)
    print("Missing values imputed with median.")
else:
    print("No missing values found.")

# Print Target Distribution
print("\nTarget Distribution:")
print(df['stress_level'].value_counts(normalize=True).round(3) * 100)

# Correlation heatmap for insights
plt.figure(figsize=(12, 10))
corr_matrix = df.corr()
sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0)
plt.title('Feature Correlation Heatmap (Post-Preprocessing)')
plt.tight_layout()
plt.show()

# ===============================
# Define features and target
# ===============================
X = df.drop('stress_level', axis=1)
y = df['stress_level']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print(f"\nTrain samples: {X_train.shape[0]} (Class dist: {np.bincount(y_train)})")
print(f"Test samples: {X_test.shape[0]} (Class dist: {np.bincount(y_test)})")

# ===============================
# Random Forest Classifier
# ===============================
rf_model = RandomForestClassifier(
    n_estimators=200,
    random_state=42,
    class_weight="balanced"  
)

# Train model
rf_model.fit(X_train, y_train)

# Predictions
y_pred_rf = rf_model.predict(X_test)

# Evaluate the model
train_accuracy = accuracy_score(y_train, rf_model.predict(X_train))
print("Train accuracy : ", train_accuracy)
test_accuracy = accuracy_score(y_test, y_pred_rf)
print("Test accuracy : ", test_accuracy)

print("\nClassification Report:")
print(classification_report(y_test, y_pred_rf))

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred_rf))

# ===============================
# Feature Importance
# ===============================
feature_importance = pd.DataFrame({
    "Feature": X.columns,
    "Importance": rf_model.feature_importances_
}).sort_values(by="Importance", ascending=False)

print("\nTop Features by Importance:")
print(feature_importance.head(10))

# Plot feature importance
plt.figure(figsize=(10, 6))
sns.barplot(x="Importance", y="Feature", data=feature_importance.head(15))
plt.title("Random Forest - Top Feature Importances")
plt.tight_layout()
plt.show()
